<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>FocoAnalytics.</title>

    <!-- box icons -->
    <link href='https://unpkg.com/boxicons@2.1.4/css/boxicons.min.css' rel='stylesheet'>
  
    <!-- custom css -->
    <link rel="stylesheet" href="static/style.css">
    <!-- Other head elements -->
    <link rel="stylesheet" href="static/secondblog/default.min.css">
    <script src="static/secondblog/highlight.js"></script>    
    <script>hljs.initHighlightingOnLoad();</script>
    <style>
     </style>
</head>
<body>
    <header class="header">
        <a href="/#home" class="logo">FocoAnalytics.</a>

        <div class='bx bx-menu' id="menu-icon"></div>

        <nav class="navbar">
            <a href="/#home" class="active home-class">Inicio</a>
            <a href="/#about" class="about-class">¿Quién soy?</a>
            <a href="/#portfolio" class="portfolio-class">Ideas</a>
        </nav>
    </header>
    <section class="blog" id="blog">
        <div class="foco_container">
            <div class="column middle">
              <h2 class="center-text"><i class="fas fa-smile"></i>¿Qué es un Docker?</h2>
              <br>
              <br>
              <br>
              <p class="blog-text"> 
              Docker es la plataforma de contenedor más utilizada en la actualizada, la cual permite la creación, ejecución y la gestión de contenedores. Los contenedores son entornos ligeros y portátiles, que empaquetan todo lo necesario para la ejecución de una aplicación, incluyendo código, librerías y dependencia.  Los contenedores permiten construir código que puede ser ejecutando en cualquier maquina, sin importar dependencias del entorno o configuraciones de sistema.
              </p>
              </p>
              <br>
              <h4 class="title-small">¿Para qué se usa Docker?</h4>
              <br>
              <br>
              <p class="blog-text"> 
                Docker es una herramienta bastante importante en el desarrollo de software, la cual se puede usar para distintas tareas, tales como:
              </p>
              <ul class="blog-text" style="padding-left: 20px;">
                <br>
                <li><strong>  Desarrollo de aplicaciones:</strong>  Docker entrega un entorno consistente para el desarrollo y pruebas de aplicaciones, generando un entorno de producción estable, reduciendo los problemas de compatibilidad e integración. </li>
                <br>
                <li><strong>  Micro servicios:</strong>  Docker es ideal en instalación de micro servicios, ya que las aplicaciones pueden ejecutarse independiente una de la otra, ejecutándose en sus propios contenedores.  En este caso, los modelos de machine learning pueden ser construidos como micro servicios, tanto para su entrenamiento como inferencia.</li>
              </ul>
              <br>
              <br>
              <h4 class="title-small">¿Qué archivos son claves para desplegar un Docker?</h4>
              <br>
              <br>
              <p class="blog-text"> 
              Para construir y desplegar un contenedor dentro de un docker, se deben considerar tres principales archivos: 
              </p>
              <ul class="blog-text" style="padding-left: 20px;">
                <br>
                <li><strong>Dockerfile:</strong>  Este archivo posiblemente es el más importante en cualquier proyecto que utilice contenedor usando docker. Este archivo contiene una serie de instrucciones a seguir para construir la imagen del docker, desde la base, comando, copiar archivos hasta variables de entorno.  </li>
                <br>
                  <li><strong>Dockerignore:</strong> Su función es determinar que elementos se deben ignorar al momento de ejecutar o construir la imagen. </li>
                <br>
                <li><strong>Requestment.txt:</strong> Su función es declarar que librerías se deben instalar al momento de construir la imagen Docker.  </li>
              </ul>
              <br>
              <br>
              <h4 class="title-small">Ejemplo Práctico: ¿Cómo construir un API de Whisper usando Docker?</h4>
              <br>
              <br>
              <p class="blog-text"> 
                Este endpoint permitirá transcribir un audio a texto, entregando el texto como resultado, más el tiempo en ejecución. Adicionalmente, construiré este docker en una máquina virtual en GCP con GPU, aplicando comandos para instalar Docker dentro de la VM, junto con comparar el rendimiento entre la velocidad de transcripción usando GPU y no tenerla. 
                
                Nota: Toda esta información se encuentra en el siguiente repositorio:
              <a href="https://github.com/Foco22/whispera-api " style="color: #673AB7;"><strong>Github</strong></a> 
                </p>
              <br>
              <br>
              <h4 class="title-small">DockerFile</h4>
              <br>
              <br>
              <p class="blog-text"> 
               Inicialmente, se construyó un dockerfile, que contiene la siguiente información:
              </p>
              <br>
              <br>
              <pre class="code-box">
FROM nvidia/cuda:12.3.2-cudnn9-runtime-ubuntu22.04

WORKDIR /code

RUN apt-get update && \
apt-get install -y python3-pip libzbar0 \
libgl1-mesa-glx

RUN apt-get update && apt-get install -y ffmpeg

COPY ./requirements.txt /code/requirements.txt
RUN pip3 install --no-cache-dir --upgrade -r \
/code/requirements.txt

RUN pip3 install torch torchvision torchaudio --extra-index-url  \
https://download.pytorch.org/whl/cuda120

# Copy main.py and servicewhisper.py to the container
COPY ./main.py /code/main.py
COPY ./servicewhisper.py /code/servicewhisper.py

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "80"]
              </pre>
              <br>
              <br>
              <p class="blog-text"> 
              Como se mencionó anteriormente, el docker es una secuencia de instrucciones. En este caso, su linea base es una imagen nvidia con CUDA instalado. Posteriormente, se instalan paquetes necesarios para que se ejecute whisper dentro del contenedor (ffmpeg). Además, contiene el comando CMD, que al iniciar el contenedor, Docker ejecutará automáticamente el comando para arrancar el servidor Uvicorn con una aplicación FastAPI. 
              </p>
              <br>
              <br>
              <h4 class="title-small">¿Qué contiene la API?</h4>
              <br>
              <br>
              <p class="blog-text"> 
                La API es capaz de recibir un archivo mp3 o un conjunto de archivos, procesarlos por el modelo de whisper para su transcripción, devolviendo un json como resultado. Para separar la transcripción del archivo main, se construyó un archivo serviceswhisper.py, el cual contiene la llamada al modelo de whisper y su ejecución.  Este archivo es simple, ya que llama al modelo, construye un archivo temporal el mp3, para luego introducirlo a whisper, y retornar el texto. 
              </p>
              <br>
              <br>
              <h4 class="title-small">¿Cómo desplegar el docker en un VM?</h4>   
              <br>
              <br>
              <p class="blog-text"> 
                Para desplegar la API, se utilizó una VM en Google para construir la imagen y ejecutar el contenedor. Google tiene maquinas con imágenes pre-instaladas de Deeplearning y drivers de NVIDIA, facilitando enormemente la ejecución de contenedores usando GPU.Para este propósito, usando mi cuenta de GPC, en la sección de Enginer Computer, alquile una maquina con GPU (Nvidia T4), con un sistema operativo “Deep Learning On Linux” (imagen). Esta maquina cuesta alrededor de 200 dólares mensuales, pero como la utilice aproximadamente una hora para este ejercicio, no fue mayor gasto.
              </p>
              <br>
              <p class="blog-text"> 
                Al instalar la maquina y conectarse por SSH al terminal, se puede comprobar que los driver de NVIDIA están instalados, ejecutando el siguiente comando en su terminal:
              </p>
              <br>
              <br>
              <pre class="code-box">
nvidia-smi
              </pre>
              <br>
              <p class="blog-text"> 
                Si no hay ningún error en el terminal, debería aparecer una imagen parecida a la siguiente:
              </p>
              <br>
              <div class="image-container">
                <img src="static/secondblog/nvidia.png">
              </div>              
              <br>
              <br>
              <p class="blog-text"> 
                Esta imagen demuestra que los driver de NVIDIA están instalados en la maquina, siendo capaz de ejecutar códigos que requieran GPU. Después, se debe instalar docker en la maquina, siguiendo los pasos descrito en el Github del repositorio. (<a href="https://github.com/Foco22/whispera-api " style="color: #673AB7;"><strong>Github </strong></a>).
              </p>             
              <br>
              <p class="blog-text"> 
              Para construir la imagen docker, se puede utilizar el siguiente comando:
              </p>  
              <br>
              <br>
              <pre class="code-box">
docker build -t whisper .
              </pre>
              <br>
              <br>    
              <p class="blog-text"> 
                Finalmente, se debe ejecutar la imagen del contenedor previamente construida. Si se requiere ejecutar con la GPU de la maquina virtual, se debe utilizar el siguiente comando:
              </p> 
              <br>
              <br>  
              <pre class="code-box">
docker run --gpus all -p 8000:80 whisper
              </pre>               
              <br>
              <br>
              <p class="blog-text"> 
                No obstante, si requiere ejecutar sin ella, se utiliza:
              </p>
              <br>
              <br>
              <pre class="code-box">
docker run -p 8000:80 whisper
              </pre>               
              <br>   
              <br>
              <p class="blog-text"> 
                Independiente de la forma de ejecutar el docker, se levantará un endpoint llamado api/whisper en el puerto 8000. Este endpoint puede ser accesible desde la misma maquina u otra de afuera de GCP configurando las reglas de firewall, mediante la creación de una nueva regla de Firewall, que permita poder acceder al puerto 8000 desde cualquier instancia en Google.
              </p>
              <br>   
              <br>
              <p class="blog-text"> 
                Dentro del github se encuentra un audio llamado audio.mp3, el cual tiene una duración alrededor de 15 minutos, y puede ser usado para la transcripción. El endpoint puede ser validado utilizado el siguiente código:              </p>
              <br>
              <br>
              <pre class="code-box">
url = 'http://Externa IP:8000/api/whisper'
files = {'files': ('filename.mp3', open('audio.mp3', 'rb'), 'audio/mpeg')}
response = requests.post(url, files=files)
              </pre> 
              <br>   
              <br>
              <p class="blog-text"> 
                Al ejecutar el código usando el comando con “–-gpu”, el tiempo de transcripción es de 45 segundos. No obstante, si se ejecuta sin gpu, el tiempo es de 190 segundos aprox, representando una aumento de un 422% respecto a tener tarjeta gráfica. 
              </p>
    </section>
    <!-- scroll reveal -->
    <script src="https://unpkg.com/scrollreveal"></script>

    <!-- typed js -->
    <script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12"></script>

    <!-- custom js -->
    <script src="static/script.js"></script>
</body>
</html>



   
